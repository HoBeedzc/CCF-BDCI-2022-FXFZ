{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a814fdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hobee/PythonScript/CCF-BDCI-2022-FXFZ\n",
      "\u001b[34m.\u001b[m\u001b[m                    dataA.csv            dataTrain.csv\n",
      "\u001b[34m..\u001b[m\u001b[m                   dataNoLabel.csv      submit_example_A.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 加载LibSVM格式数据模块\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "!pwd\n",
    "!ls -a ./raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3de5a343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/homebrew/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sklearn) (1.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.23.4)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bade3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>f40</th>\n",
       "      <th>f41</th>\n",
       "      <th>f42</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f46</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>624</td>\n",
       "      <td>1539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50408</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>high</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53228</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mid</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  f1  f2    f3  f4  f5   f6   f7  f8  f9  ...  f38  f39  f40  f41  \\\n",
       "0  81167   0   1   mid   0   0    0  153   0   0  ...    0    0    0    0   \n",
       "1  50408   1   1   mid   0   0   21    0   0   0  ...    0    0    0    0   \n",
       "2   9114   0   0  high  36  36  120    0   0   0  ...    0    0    0    0   \n",
       "3  53228   1   1   low   0   0    0    0   0   0  ...    0    0    0    0   \n",
       "4  56280   1   1   mid   9  51  294    0   0   0  ...    0    0    0    0   \n",
       "\n",
       "   f42  f43  f44  f45   f46  label  \n",
       "0    0    0    0  624  1539      0  \n",
       "1    0    0    0  186   366      0  \n",
       "2    0    0    0   24    48      1  \n",
       "3    0    0    3    3     9      0  \n",
       "4    0    0    0   42   141      0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"./raw/dataTrain.csv\")\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bacaf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label 分布情况\n",
    "ax = raw_data['label'].value_counts().plot(kind = 'bar',figsize = (12,8),fontsize=15,rot = 0)\n",
    "ax.set_ylabel('Counts',fontsize = 15)\n",
    "ax.set_xlabel('Label',fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63323f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f42_log_f43_log</th>\n",
       "      <th>f42_log_f44_log</th>\n",
       "      <th>f42_log_f45_log</th>\n",
       "      <th>f42_log_f46_log</th>\n",
       "      <th>f43_log_f44_log</th>\n",
       "      <th>f43_log_f45_log</th>\n",
       "      <th>f43_log_f46_log</th>\n",
       "      <th>f44_log_f45_log</th>\n",
       "      <th>f44_log_f46_log</th>\n",
       "      <th>f45_log_f46_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.00000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.306280</td>\n",
       "      <td>0.687180</td>\n",
       "      <td>1.012940</td>\n",
       "      <td>6.006540</td>\n",
       "      <td>18.33246</td>\n",
       "      <td>37.031040</td>\n",
       "      <td>18.502440</td>\n",
       "      <td>6.696360</td>\n",
       "      <td>0.856500</td>\n",
       "      <td>1.262340</td>\n",
       "      <td>...</td>\n",
       "      <td>180.95932</td>\n",
       "      <td>181.450580</td>\n",
       "      <td>183.609780</td>\n",
       "      <td>184.561340</td>\n",
       "      <td>7594.450580</td>\n",
       "      <td>7596.609780</td>\n",
       "      <td>7597.561340</td>\n",
       "      <td>12509.209780</td>\n",
       "      <td>12510.161340</td>\n",
       "      <td>34102.161340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.460952</td>\n",
       "      <td>0.463646</td>\n",
       "      <td>0.817353</td>\n",
       "      <td>14.969066</td>\n",
       "      <td>32.85189</td>\n",
       "      <td>56.319464</td>\n",
       "      <td>46.457007</td>\n",
       "      <td>30.548644</td>\n",
       "      <td>9.672531</td>\n",
       "      <td>12.064897</td>\n",
       "      <td>...</td>\n",
       "      <td>2518.29751</td>\n",
       "      <td>2518.316344</td>\n",
       "      <td>2518.338602</td>\n",
       "      <td>2518.345414</td>\n",
       "      <td>12695.826966</td>\n",
       "      <td>12695.442519</td>\n",
       "      <td>12695.462829</td>\n",
       "      <td>16492.535044</td>\n",
       "      <td>16492.629319</td>\n",
       "      <td>20493.268121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20003.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>40005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10002.000000</td>\n",
       "      <td>10005.000000</td>\n",
       "      <td>10006.000000</td>\n",
       "      <td>20006.000000</td>\n",
       "      <td>20007.000000</td>\n",
       "      <td>50006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>744.00000</td>\n",
       "      <td>1365.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.00000</td>\n",
       "      <td>50005.000000</td>\n",
       "      <td>50007.000000</td>\n",
       "      <td>50009.000000</td>\n",
       "      <td>80009.000000</td>\n",
       "      <td>80008.000000</td>\n",
       "      <td>80009.000000</td>\n",
       "      <td>90008.000000</td>\n",
       "      <td>90009.000000</td>\n",
       "      <td>90010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 f1            f2            f3            f4           f5  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.00000   \n",
       "mean       0.306280      0.687180      1.012940      6.006540     18.33246   \n",
       "std        0.460952      0.463646      0.817353     14.969066     32.85189   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "50%        0.000000      1.000000      1.000000      0.000000      0.00000   \n",
       "75%        1.000000      1.000000      2.000000      0.000000     27.00000   \n",
       "max        1.000000      1.000000      2.000000    267.000000    744.00000   \n",
       "\n",
       "                 f6            f7            f8            f9           f10  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean      37.031040     18.502440      6.696360      0.856500      1.262340   \n",
       "std       56.319464     46.457007     30.548644      9.672531     12.064897   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        9.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       57.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max     1365.000000    273.000000    264.000000    162.000000    237.000000   \n",
       "\n",
       "       ...  f42_log_f43_log  f42_log_f44_log  f42_log_f45_log  \\\n",
       "count  ...      50000.00000     50000.000000     50000.000000   \n",
       "mean   ...        180.95932       181.450580       183.609780   \n",
       "std    ...       2518.29751      2518.316344      2518.338602   \n",
       "min    ...          0.00000         0.000000         0.000000   \n",
       "25%    ...          0.00000         0.000000         2.000000   \n",
       "50%    ...          0.00000         0.000000         4.000000   \n",
       "75%    ...          1.00000         2.000000         5.000000   \n",
       "max    ...      50003.00000     50005.000000     50007.000000   \n",
       "\n",
       "       f42_log_f46_log  f43_log_f44_log  f43_log_f45_log  f43_log_f46_log  \\\n",
       "count     50000.000000     50000.000000     50000.000000     50000.000000   \n",
       "mean        184.561340      7594.450580      7596.609780      7597.561340   \n",
       "std        2518.345414     12695.826966     12695.442519     12695.462829   \n",
       "min           0.000000         0.000000         0.000000         0.000000   \n",
       "25%           3.000000         0.000000         2.000000         3.000000   \n",
       "50%           5.000000         0.000000         4.000000         5.000000   \n",
       "75%           6.000000     10002.000000     10005.000000     10006.000000   \n",
       "max       50009.000000     80009.000000     80008.000000     80009.000000   \n",
       "\n",
       "       f44_log_f45_log  f44_log_f46_log  f45_log_f46_log  \n",
       "count     50000.000000     50000.000000     50000.000000  \n",
       "mean      12509.209780     12510.161340     34102.161340  \n",
       "std       16492.535044     16492.629319     20493.268121  \n",
       "min           0.000000         0.000000         0.000000  \n",
       "25%           2.000000         3.000000     20003.000000  \n",
       "50%           5.000000         6.000000     40005.000000  \n",
       "75%       20006.000000     20007.000000     50006.000000  \n",
       "max       90008.000000     90009.000000     90010.000000  \n",
       "\n",
       "[8 rows x 1129 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_pre_process(raw,is_train=True):\n",
    "    data = raw.copy()\n",
    "    data[\"f3\"] = raw[\"f3\"].map({'low': 0, 'mid': 1, 'high': 2})\n",
    "    label = None\n",
    "    \n",
    "    # 暴力Feature 位置\n",
    "    loc_f = ['f1', 'f2', 'f4', 'f5', 'f6']\n",
    "    for i in range(len(loc_f)):\n",
    "        for j in range(i + 1, len(loc_f)):\n",
    "            data[f'{loc_f[i]}+{loc_f[j]}'] = data[loc_f[i]] + data[loc_f[j]]\n",
    "            data[f'{loc_f[i]}-{loc_f[j]}'] = data[loc_f[i]] - data[loc_f[j]]\n",
    "            data[f'{loc_f[i]}*{loc_f[j]}'] = data[loc_f[i]] * data[loc_f[j]]\n",
    "            data[f'{loc_f[i]}/{loc_f[j]}'] = data[loc_f[i]] / data[loc_f[j]]\n",
    "            \n",
    "    # 暴力Feature 通话\n",
    "    com_f = ['f43', 'f44', 'f45', 'f46']\n",
    "    for i in range(len(com_f)):\n",
    "        for j in range(i + 1, len(com_f)):\n",
    "            data[f'{com_f[i]}+{com_f[j]}'] = data[com_f[i]] + data[com_f[j]]\n",
    "            data[f'{com_f[i]}-{com_f[j]}'] = data[com_f[i]] - data[com_f[j]]\n",
    "            data[f'{com_f[i]}*{com_f[j]}'] = data[com_f[i]] * data[com_f[j]]\n",
    "            data[f'{com_f[i]}/{com_f[j]}'] = data[com_f[i]] / data[com_f[j]]\n",
    "            \n",
    "    # 离散化            \n",
    "    all_f = [f'f{idx}' for idx in range(1, 47) if idx != 3]\n",
    "    for col in all_f:\n",
    "        data[f'{col}_log'] = data[col].apply(lambda x: int(np.log(x)) if x > 0 else 0)\n",
    "\n",
    "    # 特征交叉        \n",
    "    log_f = [f'f{idx}_log' for idx in range(1, 47) if idx != 3]\n",
    "    for i in range(len(log_f)):\n",
    "        for j in range(i + 1, len(log_f)):\n",
    "            data[f'{log_f[i]}_{log_f[j]}'] = data[log_f[i]]*10000 + data[log_f[j]]\n",
    "    \n",
    "    data = data.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "    if is_train:\n",
    "        label = data[\"label\"]\n",
    "        del data[\"label\"]\n",
    "    del data[\"id\"]\n",
    "    \n",
    "    return data,label\n",
    "\n",
    "data,data_label = data_pre_process(raw_data)\n",
    "data = data[:50000]\n",
    "data_label = data_label[:50000]\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7748b514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#在训练集上训练\\ngrid.fit(data,data_label) #TODO : 这里把训练停了\\n#返回最优的训练器\\nbest_estimator = grid.best_estimator_\\nprint(best_estimator)\\n#输出最优训练器的精度\\nprint(grid.best_score_)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#分类器使用 xgboost\n",
    "clf1 = xgb.XGBClassifier(learning_rate=0.1,\n",
    "                      n_estimators=100,            # 树的个数--100棵树建立xgboost\n",
    "                      max_depth=6,                 # 树的深度\n",
    "                      min_child_weight = 1,        # 叶子节点最小权重\n",
    "                      gamma=0.,                    # 惩罚项中叶子结点个数前的参数\n",
    "                      subsample=0.8,               # 随机选择80%样本建立决策树\n",
    "                      colsample_btree=0.8,         # 随机选择80%特征建立决策树\n",
    "                      objective='binary:logistic', # 指定损失函数\n",
    "                      scale_pos_weight=1,          # 解决样本个数不平衡的问题\n",
    "                      random_state=27              # 随机数\n",
    "                      )\n",
    " \n",
    "#设定搜索的xgboost参数搜索范围，值搜索XGBoost的主要6个参数\n",
    "param_dist = {\n",
    "'n_estimators':range(80,200,4),\n",
    "'max_depth':range(2,15,1),\n",
    "'learning_rate':np.linspace(0.01,2,20),\n",
    "'subsample':np.linspace(0.7,0.9,20),\n",
    "'colsample_bytree':np.linspace(0.5,0.98,10),\n",
    "'min_child_weight':range(1,9,1)\n",
    "}\n",
    " \n",
    "#RandomizedSearchCV参数说明，clf1设置训练的学习器\n",
    "#param_dist字典类型，放入参数搜索范围\n",
    "#scoring = 'neg_log_loss'，精度评价方式设定为“neg_log_loss“\n",
    "#n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长\n",
    "#n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU\n",
    "grid = RandomizedSearchCV(clf1,param_dist,cv = 3,scoring = 'auc',n_iter=300,n_jobs = -1)\n",
    " \n",
    "'''\n",
    "#在训练集上训练\n",
    "grid.fit(data,data_label) #TODO : 这里把训练停了\n",
    "#返回最优的训练器\n",
    "best_estimator = grid.best_estimator_\n",
    "print(best_estimator)\n",
    "#输出最优训练器的精度\n",
    "print(grid.best_score_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d71949b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=50, \n",
    "    learning_rate=0.1,\n",
    "    max_depth=5\n",
    ")\n",
    "hgbc = HistGradientBoostingClassifier(\n",
    "    max_iter=100,\n",
    "    max_depth=5\n",
    ")\n",
    "xgbc = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    n_estimators=100, \n",
    "    max_depth=6, \n",
    "    learning_rate=0.1\n",
    ")\n",
    "cbc = CatBoostClassifier(\n",
    "    iterations=210, \n",
    "    depth=6, \n",
    "    learning_rate=0.03, \n",
    "    l2_leaf_reg=1, \n",
    "    loss_function='Logloss', \n",
    "    verbose=0\n",
    ")\n",
    "estimators = [\n",
    "    ('gbc', gbc),\n",
    "    ('hgbc', hgbc),\n",
    "    ('xgbc', xgbc),\n",
    "    ('cbc', cbc)\n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, \n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bfdd003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;gbc&#x27;,\n",
       "                                GradientBoostingClassifier(max_depth=5,\n",
       "                                                           n_estimators=50)),\n",
       "                               (&#x27;hgbc&#x27;,\n",
       "                                HistGradientBoostingClassifier(max_depth=5)),\n",
       "                               (&#x27;xgbc&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=&#x27;auc&#x27;...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None, ...)),\n",
       "                               (&#x27;cbc&#x27;,\n",
       "                                &lt;catboost.core.CatBoostClassifier object at 0x2863813f0&gt;)],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;gbc&#x27;,\n",
       "                                GradientBoostingClassifier(max_depth=5,\n",
       "                                                           n_estimators=50)),\n",
       "                               (&#x27;hgbc&#x27;,\n",
       "                                HistGradientBoostingClassifier(max_depth=5)),\n",
       "                               (&#x27;xgbc&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=&#x27;auc&#x27;...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None, ...)),\n",
       "                               (&#x27;cbc&#x27;,\n",
       "                                &lt;catboost.core.CatBoostClassifier object at 0x2863813f0&gt;)],\n",
       "                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=5, n_estimators=50)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>hgbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_depth=5)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x2863813f0&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('gbc',\n",
       "                                GradientBoostingClassifier(max_depth=5,\n",
       "                                                           n_estimators=50)),\n",
       "                               ('hgbc',\n",
       "                                HistGradientBoostingClassifier(max_depth=5)),\n",
       "                               ('xgbc',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric='auc'...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None, ...)),\n",
       "                               ('cbc',\n",
       "                                <catboost.core.CatBoostClassifier object at 0x2863813f0>)],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_model(x,y, model=None):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.2,random_state = 33)\n",
    "    ### 训练模型\n",
    "    if model == None:\n",
    "        model = xgb.XGBClassifier(learning_rate=0.1,\n",
    "                      n_estimators=100,            # 树的个数--100棵树建立xgboost\n",
    "                      max_depth=6,                 # 树的深度\n",
    "                      min_child_weight = 1,        # 叶子节点最小权重\n",
    "                      gamma=0.,                    # 惩罚项中叶子结点个数前的参数\n",
    "                      subsample=0.8,               # 随机选择80%样本建立决策树\n",
    "                      colsample_btree=0.8,         # 随机选择80%特征建立决策树\n",
    "                      objective='binary:logistic', # 指定损失函数\n",
    "                      scale_pos_weight=1,          # 解决样本个数不平衡的问题\n",
    "                      random_state=27              # 随机数\n",
    "                      )\n",
    "\n",
    "    # 拟合\n",
    "    # model.fit(x_train, y_train, eval_set = [(x_test,y_test)], eval_metric = \"auc\", early_stopping_rounds = 10,verbose = True)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model,x_train,x_test,y_train,y_test\n",
    "\n",
    "model,x_train,x_test,y_train,y_test = train_model(data,data_label,clf)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5dc1eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "with open(\"./models/stack_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model,file=file)\n",
    "\n",
    "model = pickle.load(open(\"./models/stack_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a981815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Summary:\n",
      "acc: 0.881225\n",
      "recall: 0.6386681420380244\n",
      "auc: 0.8000553192308623\n",
      "full_auc: 0.9270421726584668\n",
      "================================\n",
      "\n",
      "================================\n",
      "Summary:\n",
      "acc: 0.8623\n",
      "recall: 0.6014234875444839\n",
      "auc: 0.7760162545472385\n",
      "full_auc: 0.9073836522705244\n",
      "================================\n",
      "\n",
      "================================\n",
      "Summary:\n",
      "acc: 0.87744\n",
      "recall: 0.6311146752205292\n",
      "auc: 0.7952002899150874\n",
      "full_auc: 0.9230929012470324\n",
      "================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看训练模型准确度\n",
    "def show_auc(x,y,model):\n",
    "    pred_label = model.predict(x)\n",
    "    pred_prob = model.predict_proba(x)\n",
    "    acc = accuracy_score(y, pred_label)\n",
    "    precision = precision_score(y, pred_label)\n",
    "    recall = recall_score(y, pred_label)\n",
    "    auc = roc_auc_score(y, pred_label) # 标签计算\n",
    "    fpr,tpr,threshold=roc_curve(y,pred_prob[:,1],pos_label=1)\n",
    "    auc_all = roc_auc_score(y, pred_prob[:,1]) # 按概率计算\n",
    "    print(\"====\"*8)\n",
    "    print(\"Summary:\")\n",
    "    print(f\"acc: {acc}\\nrecall: {recall}\\nauc: {auc}\\nfull_auc: {auc_all}\")\n",
    "    print(\"====\"*8)\n",
    "    print()\n",
    "\n",
    "show_auc(x_train, y_train, model)\n",
    "show_auc(x_test, y_test, model)\n",
    "show_auc(data,data_label,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8052478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f42_log_f43_log</th>\n",
       "      <th>f42_log_f44_log</th>\n",
       "      <th>f42_log_f45_log</th>\n",
       "      <th>f42_log_f46_log</th>\n",
       "      <th>f43_log_f44_log</th>\n",
       "      <th>f43_log_f45_log</th>\n",
       "      <th>f43_log_f46_log</th>\n",
       "      <th>f44_log_f45_log</th>\n",
       "      <th>f44_log_f46_log</th>\n",
       "      <th>f45_log_f46_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>20005</td>\n",
       "      <td>20006</td>\n",
       "      <td>50006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20004</td>\n",
       "      <td>20006</td>\n",
       "      <td>20007</td>\n",
       "      <td>40006</td>\n",
       "      <td>40007</td>\n",
       "      <td>60007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>30004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>50006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>30004</td>\n",
       "      <td>30005</td>\n",
       "      <td>30006</td>\n",
       "      <td>40005</td>\n",
       "      <td>40006</td>\n",
       "      <td>50006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39880</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>198</td>\n",
       "      <td>594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>50005</td>\n",
       "      <td>50007</td>\n",
       "      <td>50008</td>\n",
       "      <td>50007</td>\n",
       "      <td>50008</td>\n",
       "      <td>70008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39881</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20002</td>\n",
       "      <td>20006</td>\n",
       "      <td>20007</td>\n",
       "      <td>20006</td>\n",
       "      <td>20007</td>\n",
       "      <td>60007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39882</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>50006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>50006</td>\n",
       "      <td>50007</td>\n",
       "      <td>50008</td>\n",
       "      <td>60007</td>\n",
       "      <td>60008</td>\n",
       "      <td>70008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39884 rows × 1129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1  f2  f3   f4   f5   f6   f7  f8  f9  f10  ...  f42_log_f43_log  \\\n",
       "0       0   1   1    0    0    0    0   0   0    0  ...                0   \n",
       "1       1   1   1    0    0    0    0   0   0    0  ...                2   \n",
       "2       0   1   0    0    0    0    0   0   0    0  ...                0   \n",
       "3       1   1   1    0    0    0    0   0   0    0  ...                0   \n",
       "4       1   1   0    0    0    0    0   0   0    0  ...                0   \n",
       "...    ..  ..  ..  ...  ...  ...  ...  ..  ..  ...  ...              ...   \n",
       "39879   0   0   1    0    0   54    0   0   0    0  ...                3   \n",
       "39880   0   1   0  144  198  594    0   0   0    0  ...                5   \n",
       "39881   0   1   0    0    0    0    0   0   0    0  ...                2   \n",
       "39882   0   1   0    0    0    0    0   0   0    0  ...                0   \n",
       "39883   0   0   0    0    0    0  126   0   0    0  ...                5   \n",
       "\n",
       "       f42_log_f44_log  f42_log_f45_log  f42_log_f46_log  f43_log_f44_log  \\\n",
       "0                    2                5                6                2   \n",
       "1                    4                6                7            20004   \n",
       "2                    0                3                4                0   \n",
       "3                    0                3                3                0   \n",
       "4                    0                5                6                0   \n",
       "...                ...              ...              ...              ...   \n",
       "39879                4                5                6            30004   \n",
       "39880                5                7                8            50005   \n",
       "39881                2                6                7            20002   \n",
       "39882                0                5                6                0   \n",
       "39883                6                7                8            50006   \n",
       "\n",
       "       f43_log_f45_log  f43_log_f46_log  f44_log_f45_log  f44_log_f46_log  \\\n",
       "0                    5                6            20005            20006   \n",
       "1                20006            20007            40006            40007   \n",
       "2                    3                4                3                4   \n",
       "3                    3                3                3                3   \n",
       "4                    5                6                5                6   \n",
       "...                ...              ...              ...              ...   \n",
       "39879            30005            30006            40005            40006   \n",
       "39880            50007            50008            50007            50008   \n",
       "39881            20006            20007            20006            20007   \n",
       "39882                5                6                5                6   \n",
       "39883            50007            50008            60007            60008   \n",
       "\n",
       "       f45_log_f46_log  \n",
       "0                50006  \n",
       "1                60007  \n",
       "2                30004  \n",
       "3                30003  \n",
       "4                50006  \n",
       "...                ...  \n",
       "39879            50006  \n",
       "39880            70008  \n",
       "39881            60007  \n",
       "39882            50006  \n",
       "39883            70008  \n",
       "\n",
       "[39884 rows x 1129 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 半监督\n",
    "raw_semi = pd.read_csv(\"./raw/dataNoLabel.csv\")\n",
    "data_semi,_ = data_pre_process(raw_semi,is_train=False)\n",
    "\n",
    "pred_label_semi = model.predict(data_semi)\n",
    "# data_semi[\"label\"] = pred_label_semi\n",
    "\n",
    "data_semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f05f364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:39:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_btree\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.93571\n",
      "[1]\tvalidation_0-auc:0.93746\n",
      "[2]\tvalidation_0-auc:0.93745\n",
      "[3]\tvalidation_0-auc:0.93897\n",
      "[4]\tvalidation_0-auc:0.93963\n",
      "[5]\tvalidation_0-auc:0.94001\n",
      "[6]\tvalidation_0-auc:0.94035\n",
      "[7]\tvalidation_0-auc:0.94065\n",
      "[8]\tvalidation_0-auc:0.94122\n",
      "[9]\tvalidation_0-auc:0.94127\n",
      "[10]\tvalidation_0-auc:0.94144\n",
      "[11]\tvalidation_0-auc:0.94152\n",
      "[12]\tvalidation_0-auc:0.94179\n",
      "[13]\tvalidation_0-auc:0.94178\n",
      "[14]\tvalidation_0-auc:0.94205\n",
      "[15]\tvalidation_0-auc:0.94248\n",
      "[16]\tvalidation_0-auc:0.94251\n",
      "[17]\tvalidation_0-auc:0.94280\n",
      "[18]\tvalidation_0-auc:0.94324\n",
      "[19]\tvalidation_0-auc:0.94361\n",
      "[20]\tvalidation_0-auc:0.94408\n",
      "[21]\tvalidation_0-auc:0.94437\n",
      "[22]\tvalidation_0-auc:0.94470\n",
      "[23]\tvalidation_0-auc:0.94500\n",
      "[24]\tvalidation_0-auc:0.94507\n",
      "[25]\tvalidation_0-auc:0.94514\n",
      "[26]\tvalidation_0-auc:0.94538\n",
      "[27]\tvalidation_0-auc:0.94566\n",
      "[28]\tvalidation_0-auc:0.94584\n",
      "[29]\tvalidation_0-auc:0.94596\n",
      "[30]\tvalidation_0-auc:0.94626\n",
      "[31]\tvalidation_0-auc:0.94651\n",
      "[32]\tvalidation_0-auc:0.94650\n",
      "[33]\tvalidation_0-auc:0.94678\n",
      "[34]\tvalidation_0-auc:0.94696\n",
      "[35]\tvalidation_0-auc:0.94715\n",
      "[36]\tvalidation_0-auc:0.94735\n",
      "[37]\tvalidation_0-auc:0.94752\n",
      "[38]\tvalidation_0-auc:0.94748\n",
      "[39]\tvalidation_0-auc:0.94771\n",
      "[40]\tvalidation_0-auc:0.94776\n",
      "[41]\tvalidation_0-auc:0.94790\n",
      "[42]\tvalidation_0-auc:0.94804\n",
      "[43]\tvalidation_0-auc:0.94817\n",
      "[44]\tvalidation_0-auc:0.94821\n",
      "[45]\tvalidation_0-auc:0.94822\n",
      "[46]\tvalidation_0-auc:0.94826\n",
      "[47]\tvalidation_0-auc:0.94836\n",
      "[48]\tvalidation_0-auc:0.94839\n",
      "[49]\tvalidation_0-auc:0.94849\n",
      "[50]\tvalidation_0-auc:0.94856\n",
      "[51]\tvalidation_0-auc:0.94863\n",
      "[52]\tvalidation_0-auc:0.94874\n",
      "[53]\tvalidation_0-auc:0.94888\n",
      "[54]\tvalidation_0-auc:0.94892\n",
      "[55]\tvalidation_0-auc:0.94892\n",
      "[56]\tvalidation_0-auc:0.94905\n",
      "[57]\tvalidation_0-auc:0.94904\n",
      "[58]\tvalidation_0-auc:0.94918\n",
      "[59]\tvalidation_0-auc:0.94930\n",
      "[60]\tvalidation_0-auc:0.94932\n",
      "[61]\tvalidation_0-auc:0.94939\n",
      "[62]\tvalidation_0-auc:0.94941\n",
      "[63]\tvalidation_0-auc:0.94945\n",
      "[64]\tvalidation_0-auc:0.94946\n",
      "[65]\tvalidation_0-auc:0.94962\n",
      "[66]\tvalidation_0-auc:0.94969\n",
      "[67]\tvalidation_0-auc:0.94979\n",
      "[68]\tvalidation_0-auc:0.94991\n",
      "[69]\tvalidation_0-auc:0.94993\n",
      "[70]\tvalidation_0-auc:0.94996\n",
      "[71]\tvalidation_0-auc:0.94996\n",
      "[72]\tvalidation_0-auc:0.94999\n",
      "[73]\tvalidation_0-auc:0.95009\n",
      "[74]\tvalidation_0-auc:0.95012\n",
      "[75]\tvalidation_0-auc:0.95017\n",
      "[76]\tvalidation_0-auc:0.95020\n",
      "[77]\tvalidation_0-auc:0.95016\n",
      "[78]\tvalidation_0-auc:0.95016\n",
      "[79]\tvalidation_0-auc:0.95018\n",
      "[80]\tvalidation_0-auc:0.95018\n",
      "[81]\tvalidation_0-auc:0.95035\n",
      "[82]\tvalidation_0-auc:0.95037\n",
      "[83]\tvalidation_0-auc:0.95037\n",
      "[84]\tvalidation_0-auc:0.95039\n",
      "[85]\tvalidation_0-auc:0.95040\n",
      "[86]\tvalidation_0-auc:0.95040\n",
      "[87]\tvalidation_0-auc:0.95047\n",
      "[88]\tvalidation_0-auc:0.95052\n",
      "[89]\tvalidation_0-auc:0.95053\n",
      "[90]\tvalidation_0-auc:0.95053\n",
      "[91]\tvalidation_0-auc:0.95055\n",
      "[92]\tvalidation_0-auc:0.95054\n",
      "[93]\tvalidation_0-auc:0.95056\n",
      "[94]\tvalidation_0-auc:0.95061\n",
      "[95]\tvalidation_0-auc:0.95062\n",
      "[96]\tvalidation_0-auc:0.95064\n",
      "[97]\tvalidation_0-auc:0.95066\n",
      "[98]\tvalidation_0-auc:0.95070\n",
      "[99]\tvalidation_0-auc:0.95069\n"
     ]
    }
   ],
   "source": [
    "# 加入之后重新训练\n",
    "data_semi_concat = pd.concat([data, data_semi]).reset_index(drop=True)\n",
    "label_semi_concat = np.append(data_label,pred_label_semi)\n",
    "\n",
    "model_semi,x_semi_train,x_semi_test,y_semi_train,y_semi_test = train_model(data_semi_concat,label_semi_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d41d1703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Summary:\n",
      "acc: 0.88065\n",
      "recall: 0.6455085001508902\n",
      "auc: 0.8019618085437906\n",
      "full_auc: 0.924386469410682\n",
      "================================\n",
      "\n",
      "================================\n",
      "Summary:\n",
      "acc: 0.8718\n",
      "recall: 0.6334519572953736\n",
      "auc: 0.7929674456534423\n",
      "full_auc: 0.9194988250072417\n",
      "================================\n",
      "\n",
      "================================\n",
      "Summary:\n",
      "acc: 0.87888\n",
      "recall: 0.6430633520449078\n",
      "auc: 0.8001487823374019\n",
      "full_auc: 0.9234092010006001\n",
      "================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_auc(x_train, y_train, model_semi)\n",
    "show_auc(x_test, y_test, model_semi)\n",
    "show_auc(data,data_label,model_semi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53898fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   f1  f2  f3  f4  f5  f6  f7  f8  f9  f10  ...  f42_log_f43_log  \\\n",
      "0   1   1   1   0   0   0   0   0   0    0  ...                0   \n",
      "1   0   1   1   0   0   0   0   0   0    0  ...                1   \n",
      "2   0   1   2   0   0   0   0   0   0    0  ...                0   \n",
      "3   0   1   1   0   0   0   0   0   0    0  ...                0   \n",
      "4   1   1   0   0   0   0   0   0   0    0  ...                0   \n",
      "\n",
      "   f42_log_f44_log  f42_log_f45_log  f42_log_f46_log  f43_log_f44_log  \\\n",
      "0                1                3                5                1   \n",
      "1                3                5                6            10003   \n",
      "2                0                2                3                0   \n",
      "3                0                2                2                0   \n",
      "4                0                4                5                0   \n",
      "\n",
      "   f43_log_f45_log  f43_log_f46_log  f44_log_f45_log  f44_log_f46_log  \\\n",
      "0                3                5            10003            10005   \n",
      "1            10005            10006            30005            30006   \n",
      "2                2                3                2                3   \n",
      "3                2                2                2                2   \n",
      "4                4                5                4                5   \n",
      "\n",
      "   f45_log_f46_log  \n",
      "0            30005  \n",
      "1            50006  \n",
      "2            20003  \n",
      "3            20002  \n",
      "4            40005  \n",
      "\n",
      "[5 rows x 1129 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试提交\n",
    "raw_A = pd.read_csv(\"./raw/dataA.csv\")\n",
    "data_A,_ = data_pre_process(raw_A,is_train=False)\n",
    "\n",
    "print(data_A.head())\n",
    "\n",
    "# pred_label_A = model_semi.predict(data_A)\n",
    "pred_label_A = model.predict(data_A)\n",
    "pred_label_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5246eac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    41548\n",
       "1     8310\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#修正概率为0.3\n",
    "# pred_prob_A = model_semi.predict_proba(data_A)[:,1]\n",
    "pred_prob_A = model.predict_proba(data_A)[:,1]\n",
    "pred_label_A_fix = pd.DataFrame([1 if i >= 0.3 else 0 for i in pred_prob_A])\n",
    "pred_label_A_fix.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "593df952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_label(data_id,label):\n",
    "    df = pd.DataFrame({'id':data_id,'label':label})\n",
    "    df.to_csv(\"./res/s.csv\",index=False)\n",
    "\n",
    "save_label(list(raw_A['id']),list(pred_prob_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123b96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8cc4fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hobee/PythonScript/CCF-BDCI-2022-FXFZ\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
