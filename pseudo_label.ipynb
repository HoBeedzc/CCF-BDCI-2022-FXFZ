{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hobee/PythonScript/CCF-BDCI-2022-FXFZ\n",
      "\u001b[34m.\u001b[m\u001b[m                           dataNoLabel.csv\n",
      "\u001b[34m..\u001b[m\u001b[m                          dataTrain.csv\n",
      "dataA.csv                   submit_example_A.csv\n",
      "dataB-209019.csv            submit_example_B-560036.csv\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,roc_auc_score,roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "!pwd\n",
    "!ls -a ./raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f42_log_f43_log</th>\n",
       "      <th>f42_log_f44_log</th>\n",
       "      <th>f42_log_f45_log</th>\n",
       "      <th>f42_log_f46_log</th>\n",
       "      <th>f43_log_f44_log</th>\n",
       "      <th>f43_log_f45_log</th>\n",
       "      <th>f43_log_f46_log</th>\n",
       "      <th>f44_log_f45_log</th>\n",
       "      <th>f44_log_f46_log</th>\n",
       "      <th>f45_log_f46_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "      <td>89742.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.343986</td>\n",
       "      <td>0.704687</td>\n",
       "      <td>0.975597</td>\n",
       "      <td>6.755566</td>\n",
       "      <td>20.369994</td>\n",
       "      <td>41.299392</td>\n",
       "      <td>30.071672</td>\n",
       "      <td>9.935281</td>\n",
       "      <td>1.771946</td>\n",
       "      <td>2.643545</td>\n",
       "      <td>...</td>\n",
       "      <td>180.985024</td>\n",
       "      <td>181.493426</td>\n",
       "      <td>183.844822</td>\n",
       "      <td>184.809320</td>\n",
       "      <td>8019.629415</td>\n",
       "      <td>8021.980812</td>\n",
       "      <td>8022.945310</td>\n",
       "      <td>13105.999443</td>\n",
       "      <td>13106.963941</td>\n",
       "      <td>36620.926188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.475039</td>\n",
       "      <td>0.456186</td>\n",
       "      <td>0.816532</td>\n",
       "      <td>25.000288</td>\n",
       "      <td>56.536499</td>\n",
       "      <td>100.426553</td>\n",
       "      <td>93.881074</td>\n",
       "      <td>58.024913</td>\n",
       "      <td>21.693476</td>\n",
       "      <td>27.187064</td>\n",
       "      <td>...</td>\n",
       "      <td>2676.772823</td>\n",
       "      <td>2676.789162</td>\n",
       "      <td>2676.810859</td>\n",
       "      <td>2676.813922</td>\n",
       "      <td>14028.286462</td>\n",
       "      <td>14027.862063</td>\n",
       "      <td>14027.878266</td>\n",
       "      <td>17919.606513</td>\n",
       "      <td>17919.695813</td>\n",
       "      <td>22546.846463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20003.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>40005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10003.000000</td>\n",
       "      <td>10006.000000</td>\n",
       "      <td>10007.000000</td>\n",
       "      <td>20007.000000</td>\n",
       "      <td>20008.000000</td>\n",
       "      <td>50007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>3231.000000</td>\n",
       "      <td>828.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60005.000000</td>\n",
       "      <td>60007.000000</td>\n",
       "      <td>60008.000000</td>\n",
       "      <td>60009.000000</td>\n",
       "      <td>90010.000000</td>\n",
       "      <td>90011.000000</td>\n",
       "      <td>90011.000000</td>\n",
       "      <td>100010.000000</td>\n",
       "      <td>100011.000000</td>\n",
       "      <td>110011.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 f1            f2            f3            f4            f5  \\\n",
       "count  89742.000000  89742.000000  89742.000000  89742.000000  89742.000000   \n",
       "mean       0.343986      0.704687      0.975597      6.755566     20.369994   \n",
       "std        0.475039      0.456186      0.816532     25.000288     56.536499   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      2.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      2.000000    450.000000   1800.000000   \n",
       "\n",
       "                 f6            f7            f8            f9           f10  \\\n",
       "count  89742.000000  89742.000000  89742.000000  89742.000000  89742.000000   \n",
       "mean      41.299392     30.071672      9.935281      1.771946      2.643545   \n",
       "std      100.426553     93.881074     58.024913     21.693476     27.187064   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       36.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max     3231.000000    828.000000    738.000000    522.000000    729.000000   \n",
       "\n",
       "       ...  f42_log_f43_log  f42_log_f44_log  f42_log_f45_log  \\\n",
       "count  ...     89742.000000     89742.000000     89742.000000   \n",
       "mean   ...       180.985024       181.493426       183.844822   \n",
       "std    ...      2676.772823      2676.789162      2676.810859   \n",
       "min    ...         0.000000         0.000000         0.000000   \n",
       "25%    ...         0.000000         0.000000         2.000000   \n",
       "50%    ...         0.000000         0.000000         4.000000   \n",
       "75%    ...         1.000000         2.000000         5.000000   \n",
       "max    ...     60005.000000     60007.000000     60008.000000   \n",
       "\n",
       "       f42_log_f46_log  f43_log_f44_log  f43_log_f45_log  f43_log_f46_log  \\\n",
       "count     89742.000000     89742.000000     89742.000000     89742.000000   \n",
       "mean        184.809320      8019.629415      8021.980812      8022.945310   \n",
       "std        2676.813922     14028.286462     14027.862063     14027.878266   \n",
       "min           0.000000         0.000000         0.000000         0.000000   \n",
       "25%           3.000000         0.000000         2.000000         3.000000   \n",
       "50%           5.000000         0.000000         5.000000         6.000000   \n",
       "75%           6.000000     10003.000000     10006.000000     10007.000000   \n",
       "max       60009.000000     90010.000000     90011.000000     90011.000000   \n",
       "\n",
       "       f44_log_f45_log  f44_log_f46_log  f45_log_f46_log  \n",
       "count     89742.000000     89742.000000     89742.000000  \n",
       "mean      13105.999443     13106.963941     36620.926188  \n",
       "std       17919.606513     17919.695813     22546.846463  \n",
       "min           0.000000         0.000000         0.000000  \n",
       "25%           2.000000         3.000000     20003.000000  \n",
       "50%           5.000000         6.000000     40005.000000  \n",
       "75%       20007.000000     20008.000000     50007.000000  \n",
       "max      100010.000000    100011.000000    110011.000000  \n",
       "\n",
       "[8 rows x 1129 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "semi_data = pd.read_csv(\"./cache/semi_label_data.csv\")\n",
    "raw_data = pd.read_csv(\"./cache/label_data.csv\")\n",
    "label_data = pd.read_csv(\"./cache/label.csv\")\n",
    "A_rank_data = pd.read_csv(\"./cache/no_label_data.csv\")\n",
    "\n",
    "data = semi_data.copy().append(A_rank_data,ignore_index=True)\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model_file_path = \"./models/stack_model.pkl\"\n",
    "model = pickle.load(open(model_file_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x,y, model=\"PlaceHolder\"):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.3,random_state = 33)\n",
    "    ### 训练模型\n",
    "    if model == \"PlaceHolder\":\n",
    "        model = xgb.XGBClassifier(learning_rate=0.1,\n",
    "                      n_estimators=100,            # 树的个数--100棵树建立xgboost\n",
    "                      max_depth=6,                 # 树的深度\n",
    "                      min_child_weight = 1,        # 叶子节点最小权重\n",
    "                      gamma=0.,                    # 惩罚项中叶子结点个数前的参数\n",
    "                      subsample=0.8,               # 随机选择80%样本建立决策树\n",
    "                      # colsample_btree=0.8,         # 随机选择80%特征建立决策树\n",
    "                      objective='binary:logistic', # 指定损失函数\n",
    "                      scale_pos_weight=1,          # 解决样本个数不平衡的问题\n",
    "                      random_state=27              # 随机数\n",
    "                      )\n",
    "\n",
    "    # 拟合\n",
    "    # model.fit(x_train, y_train, eval_set = [(x_test,y_test)], eval_metric = \"auc\", early_stopping_rounds = 10,verbose = True)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model,x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred_prob_A = model.predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89742, 1129)\n",
      "(50000, 1129)\n",
      "epoch:1,auc:0.834841631147561,last_auc:0,dalta:0.834841631147561\n",
      "(67330, 1129)\n",
      "(72412, 1129)\n",
      "epoch:2,auc:0.8351588163198651,last_auc:0.834841631147561,dalta:0.0003171851723040575\n",
      "(67330, 1129)\n",
      "(72412, 1129)\n",
      "epoch:3,auc:0.8348323534526361,last_auc:0.8351588163198651,dalta:-0.00032646286722903817\n",
      "(67330, 1129)\n",
      "(72412, 1129)\n",
      "epoch:4,auc:0.8345791491650397,last_auc:0.8348323534526361,dalta:-0.0002532042875963425\n",
      "(67330, 1129)\n",
      "(72412, 1129)\n",
      "epoch:5,auc:0.8346614436341048,last_auc:0.8345791491650397,dalta:8.229446906504734e-05\n",
      "(67330, 1129)\n",
      "(72412, 1129)\n",
      "stop at epoch:6!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;gbc&#x27;,\n",
       "                                GradientBoostingClassifier(max_depth=5,\n",
       "                                                           n_estimators=50)),\n",
       "                               (&#x27;hgbc&#x27;,\n",
       "                                HistGradientBoostingClassifier(max_depth=5)),\n",
       "                               (&#x27;xgbc&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=&#x27;auc&#x27;...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None, ...)),\n",
       "                               (&#x27;cbc&#x27;,\n",
       "                                &lt;catboost.core.CatBoostClassifier object at 0x1545798d0&gt;)],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;gbc&#x27;,\n",
       "                                GradientBoostingClassifier(max_depth=5,\n",
       "                                                           n_estimators=50)),\n",
       "                               (&#x27;hgbc&#x27;,\n",
       "                                HistGradientBoostingClassifier(max_depth=5)),\n",
       "                               (&#x27;xgbc&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=&#x27;auc&#x27;...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None, ...)),\n",
       "                               (&#x27;cbc&#x27;,\n",
       "                                &lt;catboost.core.CatBoostClassifier object at 0x1545798d0&gt;)],\n",
       "                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=5, n_estimators=50)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>hgbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingClassifier(max_depth=5)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cbc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x1545798d0&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('gbc',\n",
       "                                GradientBoostingClassifier(max_depth=5,\n",
       "                                                           n_estimators=50)),\n",
       "                               ('hgbc',\n",
       "                                HistGradientBoostingClassifier(max_depth=5)),\n",
       "                               ('xgbc',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric='auc'...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None, ...)),\n",
       "                               ('cbc',\n",
       "                                <catboost.core.CatBoostClassifier object at 0x1545798d0>)],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 思路 循环训练 每次将label为概率大于90%的加入训练集重新训练 直到结果无法提升\n",
    "scope = 0.95\n",
    "last_auc = 0\n",
    "epoch = 1\n",
    "print(data.shape)\n",
    "print(raw_data.shape)\n",
    "while True:\n",
    "    pb = model.predict_proba(data)\n",
    "    pos_item = data[pb[:,0] > scope]\n",
    "    neg_item = data[pb[:,1] > scope]\n",
    "    raw_data = raw_data.append(pos_item,ignore_index=True)\n",
    "    raw_data = raw_data.append(neg_item,ignore_index=True)\n",
    "    label_data = label_data.append(\n",
    "        pd.DataFrame({\"label\": [1 for i in range(pos_item.shape[0])]}),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    label_data = label_data.append(\n",
    "        pd.DataFrame({\"label\": [1 for i in range(neg_item.shape[0])]}),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    data = data.drop(pos_item.index,inplace=False)\n",
    "    data = data.drop(neg_item.index,inplace=False)\n",
    "    model,x_train,x_test,y_train,y_test = train_model(raw_data,label_data,model)\n",
    "    if epoch != 1:\n",
    "        last_auc = auc\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(x_test)[:,1])\n",
    "    delta = auc - last_auc\n",
    "    print(f\"epoch:{epoch},auc:{auc},last_auc:{last_auc},dalta:{auc - last_auc}\")\n",
    "    print(data.shape)\n",
    "    print(raw_data.shape)\n",
    "    epoch += 1\n",
    "    if abs(delta) < 0.0001 or epoch == 30:\n",
    "        print(f\"stop at epoch:{epoch}!\")\n",
    "        break\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(\"./models/rankB_stack_pesudo_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model,file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
